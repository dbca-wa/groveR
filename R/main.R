# Main functions

#' A function to turn vegetation index raster data into a vegetation density
#' raster for further analysis.
#'
#' \code{veg_dens} takes an annual series of vegetation index raster mosaics and
#'     converts them to a vegetation density (cover) product.
#'
#' @details Density to vegetation index relationship must be established through
#'     prior analysis and the calibration file will provide the coefficients
#'     from this. The calibration file is a simple csv with a value in 5 columns
#'     named as follows:
#' \itemize{
#'   \item coef - the coefficient of the regression
#'   \item intercept -  the intercept of the regression
#'   \item multiple - a value to multiply by to bring output to a percentage
#'   \item lower - lower limit of acceptable vegetation density
#'   \item upper - upper limit of acceptable vegetation density
#' }
#'      All input raster mosaics should have the same extents and cell size. Whilst it
#'      won't affect the performance of this function, downstream processing will
#'      fail. See package vignette for full explanation of processing work flow.
#'
#'      Input raster mosaics can follow any naming convention that makes sense to
#'      the project but must contain a 4 digit representation of the year and
#'      contain NO other numerals. An example might be "lgcsmp_ndvi_2023.tif".
#'
#' @param irast Character file path to input vegetation index rasters.
#' @param areaname Character vector representing the geographical area that the
#'      user is processing, e.g. marine park name. This will become part of the
#'      named interim data sets and should be brief and contain no spaces or
#'      underscores. Acronyms are good.
#' @param ext Character representation of the input file type. Defaults to ".tif"
#'      as this is the preferred file type.
#' @param calibration Character representation of the name of the calibration
#'      csv file including file path. Defaults to "./supplementary/calibration.csv"
#'      which works with the suggested project folder structure and workflow.
#'
#' @return For each input raster a vegetation density raster of the same will be
#'     written to file in a folder named `veg_dens/`.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' veg_dens(irast = "Z:/DEC/projectXX/mosaics", areaname = "lgcsmp")
#'     }
#'
#' @import dplyr
#' @import cli
#' @importFrom fs dir_ls
#' @importFrom readr parse_number read_csv
#' @importFrom terra rast lapp classify writeRaster
#' @importFrom tools file_ext
#'
#' @export

veg_dens <- function(irast, areaname, ext = ".tif",
                     calibration = "./supplementary/calibration.csv"){
  cli::cli_alert_info("Converting index rasters to vegetation density")
  # starting df of I/O paths
  rastdf <- dplyr::tibble(path = fs::dir_ls(irast, glob = paste0("*", ext, "$"))) |>
    dplyr::mutate(yr = readr::parse_number(basename(path))) |>
    dplyr::arrange(yr) |>
    dplyr::mutate(outname = paste0(areaname, "_vdens_", yr, ".tif"))

  suppressWarnings({
  # calibration file
  calib <- readr::read_csv(calibration, col_types = readr::cols())
  # density formula
  coef <- calib[["coef"]]
  intercept <- calib[["intercept"]]
  multiple <- calib[["multiple"]]
  vdens <- function(x) (((x * coef) + intercept) * multiple)
  # cleaning matrix
  rcl <- c(-Inf, calib[["lower"]] + 1, NA,
           calib[["upper"]] + 1 , Inf, NA)
  rcl_mat <- matrix(rcl, ncol = 3, byrow = TRUE)
  # output folder
  out <- "./veg_dens"
  if (!file.exists(out)) {dir.create(out)}
  # process rasters
  cli::cli_progress_bar("Processing index rasters", total = length(rastdf[["path"]]))
  for(i in seq_along(rastdf[["path"]])){
    # index raster
    ir1 <- terra::rast(rastdf[['path']][i])
    # apply density function per pixel
    ir2 <- terra::lapp(ir1, fun = vdens)
    # clean up values
    ir3 <- terra::classify(ir2, rcl_mat)
    # write output to file
    fname <- paste0(out, "/", rastdf[['outname']][i])
    # change extension in case index image different to tif
    fname <- gsub(tools::file_ext(fname), tools::file_ext(ext), fname)
    terra::writeRaster(ir3, filename = fname,
                       overwrite = TRUE)
    cli::cli_progress_update()
  }
  })
}

#' A function to apply common masks to rasters
#'
#' \code{general_mask} takes one or multiple input rasters and applies
#'     pre-generated mask/s to exclude areas or clean up rasters.
#'
#' @details When producing raster products for an area there are often regions
#'     that occur at every time step that are not required for further analysis.
#'     Things like water bodies or non-target vegetation are examples. A folder
#'     full of different raster masks can be applied with this function. This
#'     function will apply all masks to all data time steps.
#'
#'     Masks are a raster indicating spatially where values of interest are.
#'     Masks must contain only 1's and 0 values. A value of 1 indicates
#'     the areas of interest. A land mask to exclude vegetation inland of the
#'     mangroves would contain a 0 for this vegetation and a 1 for the mangroves
#'     and everything else.
#'
#' @param irast Character file path to directory veg density input rasters.
#' @param imask Character file path to directory of raster masks to apply.
#' @param ext Character representation of the file extension of the raster
#'     masks. Defaults to ".tif" as this is the preferred file type.
#' @param mval Numeric indicating the value to mask, e.g. a 0 indicates to mask
#'    out this value occurs in the mask.
#'
#' @return For each input raster a masked product will be written to file in a
#'     folder named `veg_dens_mskd/`. Masked values will now be NA.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' general_mask(irast = "./veg_dens", imask = "./raster_masks")
#' }
#'
#' @import dplyr
#' @import cli
#' @importFrom fs dir_ls
#' @importFrom stringr str_replace str_detect
#' @importFrom readr parse_number
#' @importFrom terra rast mask writeRaster
#'
#' @export
general_mask <- function(irast, imask, ext = ".tif", mval = 0){
  cli::cli_alert_info("Performing general masking")
  # starting df of I/O paths
  rastdf <- dplyr::tibble(path = fs::dir_ls(irast, glob = paste0("*", ext, "$"))) |>
    dplyr::mutate(yr = readr::parse_number(basename(path))) |>
    dplyr::arrange(yr) |>
    dplyr::mutate(outname = stringr::str_replace(basename(path), "vdens",
                                                 "vdensmskd"))
  # df of mask paths
  maskdf <-  dplyr::tibble(path = fs::dir_ls(imask, glob = paste0("*", ext, "$")))
  # output folder
  out <- "./veg_dens_mskd"
  if (!file.exists(out)) {dir.create(out)}
  cli::cli_progress_bar("Processing all images...", total = length(rastdf[["path"]]))
  for(i in seq_along(rastdf[["path"]])){
    ir1 <-  terra::rast(rastdf[["path"]][i])
    for(j in seq_along(maskdf)){
      m <- terra::rast(maskdf[["path"]][j])
      ir1 <- terra::mask(ir1, m, maskvalues = mval)
    }
    mskdname <- paste0(out, "/", rastdf[['outname']][i])
    terra::writeRaster(ir1, filename = mskdname, overwrite = TRUE)
    cli::cli_progress_update()
  }
}

#' A function to create a cloud mask from a shape file
#'
#' \code{make_mask} takes an input polygon shape file and converts to a raster
#'    mask.
#'
#' @details Input raster mosaics will inevitably contain the odd cloud or smoke
#'    haze that obscures regions of interest. The user should create a polygon
#'    shape file that identifies where the cloud is within the image as this
#'    identifies where we have less certainty in our analysis. The user digitises
#'    a polygon that surrounds the cloud and ensures that each polygon contains
#'    an attribute called 'year' which has a 4 digit representation of the year
#'    of the afflicted image.
#'
#'    On running the function it will generate a raster mask for each unique year
#'    it finds in the attribute table, formatting them to the exact requirements for
#'    use in the \code{link{cloud_mask}} function. Correct extents, cell sizes, CRS
#'    and mask values are all handled within the function.
#'
#'    Note that it is possible to use this function to create other masks, such
#'    as the land mask. To do this follow the instructions and then rename and
#'    relocate the product as required.
#'
#' @param ivect Character string of the file path and name of the input
#'    shape file.
#' @param refimage Character string of the file path and name of a raster
#'    that has the correct extent and cell size for the current analysis, e.g.
#'    this could be one of the input rasters for \code{link{veg_dens}}.
#' @param attribname Character string of the name of the attribute column in the
#'    shape file that gives the year that the polygon applies to. Defaults to
#'    "year".
#' @param loc Character string of the file path to the directory where the output/s
#'    should be written. Defaults to"raster_masks/cloud_masks" which works with
#'    the suggested project folder structure and workflow.
#'
#' @return cloud masks will be written to "raster_masks/cloud_masks" unless unless
#'    'loc' parameter is changed, as tif files.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' make_mask(ivect = ""vectors/cloud_new.shp", refimage = "veg_dens/LgCSMP_vdens_2018.tif"
#' }
#'
#' @import terra
#' @importFrom tidyterra filter
#'
#' @export
make_mask <- function(ivect, refimage, attribname = "year", loc ="raster_masks/cloud_masks"){
  cv <- terra::vect(ivect) |>
    terra::project("EPSG:3577")
  rf <- terra::rast(refimage)
  yrs <- unique(cv[[attribname]][[1]])
  for(i in seq_along(yrs)){
    yr <- yrs[i]
    cm <- cv |>
      tidyterra::filter(get(attribname) == yr) |>
      terra::rasterize(rf)
    cm <- terra::subst(cm, NA, 0)
    cmname <- paste0(loc, "/cld_msk_", yr, ".tif")
    terra::writeRaster(cm, cmname)
  }
}

#' A function to apply cloud masks to rasters.
#'
#' \code{cloud_mask} applies pre-generated annual cloud masks to appropriate input
#'     rasters and replaces values with -99.
#'
#' @details The function applies a pre-generated mask to a single raster. These
#'     masks are often for things like cloud and shadow but could include something
#'     like a fire scar that could throw out the conversion to vegetation products.
#'     These circumstances are pertinent to one time step only, so the masks used
#'     here will be matched to the correct input by a year in the file name.
#'
#'     This function is designed to sort through a complete time series of input
#'     rasters and work out which need masking based on the presence of masks in
#'     a separate directory.
#'
#'     The function will compare any newly masked rasters to the raster of
#'     the year before in order to clean up masked areas that might extend over
#'     water for example. Masked areas in the product have a value of -99 and
#'     this step ensures that previously "NA" masked areas don't now have a -99
#'     value.
#'
#'     Masking of the very first input raster of a time series is handled without
#'     this step as there is no prior image to compare to. Any input raster with
#'     no requirement for masking is renamed and copied to the output directory.
#'
#'     It is vital that all input rasters and masks have the same extents, CRS
#'     and cell size and this is most easily achieved if the masks have been
#'     generated using \code{link{make mask}}.
#'
#' @param irast Character file path to directory of input rasters, most commonly,
#'     those created by \code{link{mask_product}} and stored at
#'     `veg_dens_mskd/`.
#' @param imask Character file path to directory of cloud raster masks to
#'     apply. Commonly something like "raster_masks/cloud_masks".
#' @param ext Character representation of the file extension of the raster
#'     masks. Defaults to ".tif" as this is the preferred file type.
#'
#' @return Any cloud masking will carried out to affected input rasters and
#'     these will be written to `veg_dens_mskd_cld/`. cloud masked
#'     areas will have a -99 value.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' cloud_mask(irast = "veg_dens_mskd", imask = ""raster_masks/cloud_masks")
#' }
#'
#' @import dplyr
#' @import cli
#' @importFrom fs dir_ls file_copy
#' @importFrom stringr str_replace
#' @importFrom readr parse_number
#' @import terra
#'
#' @export
cloud_mask <- function(irast, imask, ext = ".tif"){
  cli::cli_alert_info("Performing cloud masking")
  # starting df of I/O paths
  rastdf <- dplyr::tibble(path = fs::dir_ls(irast, glob = paste0("*", ext, "$"))) |>
    dplyr::mutate(outname = stringr::str_replace(path, "_mskd", "_mskd_cld"),
                  outname = stringr::str_replace(outname, "vdensmskd", "vdensmskdcld"),
                  yr = readr::parse_number(basename(path))) |>
    dplyr::arrange(yr)
  # df of mask paths
  maskdf <-  dplyr::tibble(path = fs::dir_ls(imask, glob = paste0("*", ext, "$"))) |>
    dplyr::mutate(yr = readr::parse_number(basename(path)))
  # working df of all paths
  jdf <- dplyr::left_join(rastdf, maskdf, by = "yr") |>
    dplyr::mutate(cloud = !is.na(path.y))
  # mask only df
  mdf <- jdf |>
    dplyr::filter(cloud == TRUE)
  # non-mask only df
  clr_df <- jdf |>
    dplyr::filter(cloud != TRUE)
  # output folder
  out <- "./veg_dens_mskd_cld"
  if (!file.exists(out)) {dir.create(out)}
  # function for trimming mask using reference image to NAs
  cldfun = function(x1, x2){
    ifelse(is.na(x1) & is.na(x2), NA,
           ifelse(x2 == -99 & is.na(x1), x1, x2))}
  # deal with non- cloud affected images (i.e. just rename and move)
  cli::cli_progress_step("Copying and renaming non-cloudy images...")
  fs::file_copy(clr_df[[1]], clr_df[[2]], overwrite=TRUE)
  # mask cloudy images with -99
  cli::cli_progress_bar("Masking cloud", total = length(mdf[[1]]))
  for(i in seq_along(mdf[[1]])){
    # year to mask
    myr <- mdf[["yr"]][i]
    # path to cloudy year to mask
    cld_im <- mdf |>
      dplyr::filter(yr == myr) |>
      dplyr::pull(path.x)
    # non-cloudy years available as reference for cropping
    nonyr <- clr_df[["yr"]]
    # path to earliest year as reference image
    ref_im <- clr_df |>
      dplyr::filter(yr == nonyr[which.min(abs(nonyr - myr))]) |>
      dplyr::pull(path.x)
    # cloudy mask name
    cs_n <- mdf |>
      dplyr::filter(yr == myr) |>
      dplyr::pull(path.y)
    # cloudy mask
    cs_msk <- terra::rast(cs_n)
    csmax <- terra::minmax(cs_msk)[[2]]
    # cloudy raster to do, put in cloud
    c_rst <- terra::rast(cld_im)
    cs_msk <- terra::classify(cs_msk, cbind(csmax, -99))
    cs_msk <- terra::subst(cs_msk, 0, NA)
    o_rst <- terra::cover(cs_msk, c_rst)
    # bring in reference image
    ref_rst <- terra::rast(ref_im)
    st <- c(ref_rst, o_rst)
    # now clean up based on prior image
    clean_rst <- terra::lapp(st, fun = cldfun)
    # write out data
    terra::writeRaster(clean_rst, filename = mdf[["outname"]][i], overwrite = TRUE)
    cli::cli_progress_update()
  }
}

#' A function to perform vegetation classifications
#'
#' \code{veg_class} performs a raster reclassification based on a user supplied
#'     set of meaningful bins.
#'
#' @details This function is designed to take the continuous values, in say a
#'     raster of vegetation densities, and convert them to numeric classes based
#'     on some prior determination. The user must supply a csv of density
#'     classes with the following three column format so that each row forms a
#'     bin:
#' \itemize{
#'   \item lower - numerical low value for bin
#'   \item upper - numerical high value (<=) for bin
#'   \item reclass - numerical classification value
#'   }
#'
#'    The numerical classification can take any single integer value except
#'    6. The integer 6 is reserved for any values that had a masked value of -99
#'    created by using the "cloud_mask" functions.
#'
#'    The function can also perform some "probable" value classification in
#'    areas that are masked with a -99 value. It will identify the same pixels
#'    in the previous year's raster and return those classified values plus 10.
#'    The reasoning here is that those pixels possibly would not have changed
#'    density but they can still be identified and removed (e.g. any value > 10)
#'    in downstream analysis.
#'
#' @param irast Character file path to input veg density rasters that have been
#'     through the masking process, i.e. those that are found in
#'     `veg_dens_mskd\` or `veg_dens_mskd_cld\`.
#' @param rastkey Character representation of unique string to match in intended
#'     rasters. This aids in not selecting additional files generated by other
#'     software (e.g. ArcMap).
#' @param imask A character file path to directory of raster masks that were
#'     created using a "cloud_mask" function if a "probable" classification is
#'     desired. If there were none or you would prefer that no "probable"
#'     classifications be carried out use FALSE.
#' @param maskkey Character representation of the file extension of the raster
#'     masks if a "probable" classification is desired. If not use NA
#' @param classes Character representation of the name of the density classes
#'     csv file including file path.
#'
#' @return All input rasters will be reclassified and be written to either
#'     `veg_class_cloud_prob/` for "probable" classifications or `veg_class/` if
#'     standard classifications are carried out.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' veg_class(irast = "./veg_dens_mskd", rastkey = ".tif",
#'     imask = FALSE, maskkey = NA,
#'     classes = "./supplementary/density_classes.csv")
#' }
#'
#' @import dplyr
#' @importFrom magrittr %>%
#' @importFrom fs dir_ls file_copy
#' @importFrom stringr str_replace
#' @importFrom readr parse_number read_csv
#' @importFrom terra rast writeRaster classify lapp
#'
#' @export
veg_class <- function(irast, rastkey, imask, maskkey, classes){
  suppressWarnings({
    # get classes
    if(file.exists(classes) == FALSE) stop("classes csv must exist")
    cl <- as.matrix(readr::read_csv(classes))
    if(dim(cl)[2] !=3) stop("check that classes csv has 3 columns")
    # dealing with first image cloudy?
    if(imask == FALSE){
      rastdf <- dplyr::tibble(path = fs::dir_ls(irast,
                                                glob = paste0("*",
                                                              rastkey,
                                                              "$"))) %>%
        dplyr::mutate(pathnew = stringr::str_replace(path, "dens_mskd",
                                                     "class"),
                      pathnew = stringr::str_replace(pathnew, "V_Dens_Mskd",
                                                     "Veg_Class"),
                      year = readr::parse_number(basename(path)))

      maskdf <- dplyr::tibble(path = NA, year = NA)

    } else {
      rastdf <- dplyr::tibble(path = fs::dir_ls(irast,
                                                glob = paste0("*",
                                                              rastkey,
                                                              "$"))) %>%
        dplyr::mutate(pathnew = stringr::str_replace(path, "dens_mskd_cld",
                                                     "class_cloud_prob"),
                      pathnew = stringr::str_replace(pathnew, "V_Dens_MskdCld",
                                                     "Veg_Class_Cloud_Probabilities"),
                      year = readr::parse_number(basename(path)))

      maskdf <- dplyr::tibble(path = fs::dir_ls(imask,
                                                glob = paste0("*",
                                                              maskkey, "$"))) %>%
        dplyr::mutate(year = readr::parse_number(basename(path)))
    }

    jdf <- dplyr::left_join(rastdf, maskdf, by = "year") %>%
      dplyr::mutate(cloud = !is.na(path.y))

    if(imask == FALSE){
      out <- "./veg_class"
    } else {
      out <- "./veg_class_cloud_prob"
    }
    if (!file.exists(out)) {dir.create(out)}
    if(jdf$cloud[[1]] == TRUE){
      # deal with first of time series having clouds but no prior year reference image
      s_rast <- terra::rast(jdf[[1]][1])
      cat("Classifying...", basename(jdf[[1]][1]), "\n")
      rcl <- terra::classify(s_rast, cl)
      # grab a non cloudy to effect some masking
      nci <- jdf %>%
        dplyr::filter(cloud == FALSE) %>%
        dplyr::pull(path.x)
      nci <- nci[1]
      nci_rst <- terra::rast(nci)
      st <- c(nci_rst, rcl)
      mskfun = function(x1, x2){
        ifelse(x2 == 6 & is.na(x1), NA, x2)
      }
      cl_rst <- terra::lapp(st, fun = mskfun)

      terra::writeRaster(x = cl_rst, filename = jdf[[2]][1], datatype = 'INT1U',
                         overwrite=TRUE)

      # classify non cloud affected images
      jdf2 <- jdf %>%
        dplyr::filter(cloud == FALSE)
      for(i in seq_along(jdf2[[1]])){
        cat("Classifying...", basename(jdf2[[1]][i]), "\n")
        rst <- terra::rast(jdf2[[1]][i])
        rcl <- terra::classify(rst, cl)
        terra::writeRaster(x = rcl, filename = jdf2[[2]][i], datatype = 'INT1U',
                           overwrite=TRUE)
      }
      # classify cloudy using previous image
      # a df without first image
      jdf_short <- jdf %>%
        dplyr::slice(-1)#important for when first image is cloudy
      cloud_yrs <- jdf_short %>%
        dplyr::filter(cloud == TRUE) %>%
        dplyr::pull(year)
      # function for later
      cldfun2 = function(x1, x2){
        ifelse(is.na(x1) & is.na(x2), NA,
               ifelse(x2 == 6 & is.na(x1), x1,
                      ifelse(x2 == 6 & !is.na(x1), x1 + 10, x2)))}
      for(j in seq_along(cloud_yrs)){
        yr <- cloud_yrs[j]
        c_n <- jdf %>%
          dplyr::filter(year == yr) %>%
          dplyr::pull(path.x)
        cat("Classifying...", basename(c_n), "\n")
        p_n <- jdf %>%
          dplyr::filter(year == yr - 1) %>%
          dplyr::pull(pathnew)#bring in classified image
        # current cloudy raster
        c_rst <- terra::rast(c_n)
        # classify it
        c_rst_c <- terra::classify(c_rst, cl)
        # previously already classified yr
        p_rst <- terra::rast(p_n)
        # stack it
        st <- c(p_rst, c_rst_c)
        # now clean up based on prior image
        clean_rst <- terra::lapp(st, fun = cldfun2)
        o_n <- jdf %>%
          dplyr::filter(year == yr) %>%
          dplyr::pull(pathnew)
        terra::writeRaster(x = clean_rst, filename = o_n, datatype = "INTU",
                           overwrite = TRUE)
      }

    } else {
      # no cloudy first image so move straight on
      # classify non cloud affected images
      jdf2 <- jdf %>%
        dplyr::filter(cloud == FALSE)
      for(i in seq_along(jdf2[[1]])){
        cat("Classifying...", basename(jdf2[[1]][i]), "\n")
        rst <- terra::rast(jdf2[[1]][i])
        rcl <- terra::classify(rst, cl)
        terra::writeRaster(x = rcl, filename = jdf2[[2]][i], datatype = 'INT1U',
                           overwrite=TRUE)
      }
      # classify cloudy using previous image
      cloud_yrs <- jdf %>%
        dplyr::filter(cloud == TRUE) %>%
        dplyr::pull(year)
      # function for later
      cldfun2 = function(x1, x2){
        ifelse(is.na(x1) & is.na(x2), NA,
               ifelse(x2 == 6 & is.na(x1), x1,
                      ifelse(x2 == 6 & !is.na(x1), x1 + 10, x2)))}
      for(j in seq_along(cloud_yrs)){
        yr <- cloud_yrs[j]
        c_n <- jdf %>%
          dplyr::filter(year == yr) %>%
          dplyr::pull(path.x)
        cat("Classifying...", basename(c_n), "\n")
        p_n <- jdf %>%
          dplyr::filter(year == yr - 1) %>%
          dplyr::pull(pathnew)#bring in classified image
        # current cloudy raster
        c_rst <- terra::rast(c_n)
        # classify it
        c_rst_c <- terra::classify(c_rst, cl)
        # previously already classified yr
        p_rst <- terra::rast(p_n)
        # stack it
        st <- c(p_rst, c_rst_c)
        # now clean up based on prior image
        clean_rst <- terra::lapp(st, fun = cldfun2)
        o_n <- jdf %>%
          dplyr::filter(year == yr) %>%
          dplyr::pull(pathnew)
        terra::writeRaster(x = clean_rst, filename = o_n, datatype = "INTU",
                           overwrite = TRUE)
      }
    }
  })
}


#' A function to calculate vegetation classification area for reporting.
#'
#'  \code{veg_class_area} calculates classified areas.
#'
#' @details This function is designed to calculate the area of each class as
#'     defined by using the \code{\link{veg_class}} per reporting area or site.
#'     Reporting areas are defined by input shape file. Output results to csv.
#'
#' @param irast Character file path to input veg density rasters that have been
#'     through the veg classification process, i.e. those that are found in
#'     `veg_class_cloud_prob\` or `veg_class\`.
#' @param rastkey Character representation of unique string to match in intended
#'     rasters. This aids in not selecting additional files generated by other
#'     software (e.g. ArcMap).
#' @param iregions Character file path to a shape file (including extension)
#'     that defines reporting regions. The shape file should have an attribute
#'     column that defines the overall reporting "region" plus "site", if
#'     applicable, such as "NatPark_site1", "NatPark_site2" etc. The underscore
#'     delineates region from site.
#' @param attribname Character string of the name of the attribute column that
#'     contains the region information.
#'
#' @param areaname Character string of desired monitoring area name for inclusion
#'     to output csv name.
#'
#' @return Calculated areas are exported via csv file to `extent_summaries\`.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' veg_class_area(irast = "./veg_class_cloud_prob", rastkey = ".tif",
#'     iregions = "./vectors/regions.shp", attribname = "regions",
#'     areaname = "NKMP_all")
#' }
#'
#' @import dplyr
#' @importFrom magrittr %>%
#' @importFrom fs dir_ls
#' @importFrom stringr str_split
#' @importFrom terra rast vect res rasterize mask freq
#' @importFrom readr write_csv
#'
#' @export
veg_class_area <- function(irast, rastkey, iregions, attribname, areaname){
  suppressWarnings({
    irs <- fs::dir_ls(irast, glob = paste0("*", rastkey, "$"))
    rastdf <- dplyr::tibble(path = irs) %>%
      dplyr::mutate(yr = readr::parse_number(basename(path))) #%>%
    #dplyr::filter(!yr %in% dummies)
    regions <- terra::vect(iregions)
    reps <- unique(regions[[attribname]][[1]])
    # output folder
    out <- "./extent_summaries"
    if (!file.exists(out)) {dir.create(out)}
    # stack rasters
    rsk <- terra::rast(rastdf[[1]])
    # find pixel res and calculate hectares
    res_mult <- (round(terra::res(rsk)[1])^2)/10000
    stats <- dplyr::tibble()
    cat("Calculating veg classes... \n")
    for(i in seq_along(reps)){
      rep_i <- regions[i, attribname]
      cat("Doing...", reps[i], "\n")
      name_r <- stringr::str_split(reps[i], "_")[[1]][1]
      name_s <- stringr::str_split(reps[i], "_")[[1]][2]
      # make raster mask
      rep_ir <- terra::rasterize(x = rep_i, y = rsk[[1]])
      # mask out
      msk_ir <- terra::mask(rsk, rep_ir)
      names(msk_ir) <- rastdf[[2]]
      # calc freq
      stk <- terra::freq(msk_ir, usenames = TRUE)
      out_df <- stk %>%
        dplyr::mutate(Region = name_r,
                      Site = name_s,
                      Area = count * res_mult,
                      DensityClass = dplyr::case_when(
                        value == 1 ~ '10-19%',
                        value == 2 ~ '20-29%',
                        value == 3 ~ '30-49%',
                        value == 4 ~ '50-69%',
                        value == 5 ~ '70-100%',
                        value == 6 ~ 'Cloud',
                        value == 11 ~ 'Cloud 10-19%',
                        value == 12 ~ 'Cloud 20-29%',
                        value == 13 ~ 'Cloud 30-49%',
                        value == 14 ~ 'Cloud 50-69%',
                        value == 15 ~ 'Cloud 70-100%',
                        TRUE ~ "Other"
                      ),
                      Habitat = dplyr::case_when(
                        value == 1 ~ "Very Sparse Mangroves",
                        value >= 2 & value <= 5 ~ "Mangroves",
                        value == 6 ~ "Cloud",
                        value == 11 ~ "Cloud likely Very Sparse Mangroves",
                        value >= 12 & value <= 15 ~ "Cloud likely Mangrove",
                        TRUE ~ "Other"
                      ),
                      Density = dplyr::case_when(
                        value == 1 ~ "Very Sparse",
                        value == 2 ~ "Sparse",
                        value == 3 ~ "Sparse - Medium",
                        value == 4 ~ "Medium - Dense",
                        value == 5 ~ "Dense",
                        value == 6 ~ "Cloud",
                        value == 11 ~ "Cloud likely Very Sparse",
                        value == 12 ~ "Cloud likely Sparse",
                        value == 13 ~ "Cloud likely Sparse - Medium",
                        value == 14 ~ "Cloud likely Medium - Dense",
                        value == 15 ~ "Cloud likely Dense",
                        TRUE ~ "Other")) %>%
        dplyr::rename(Year = layer) %>%
        dplyr::select(-count, -value)
      stats <- dplyr::bind_rows(stats, out_df)
    }
    # find start end year
    ayrs <- unique(stats$Year)
    yrs <- paste0("_", min(ayrs), "-", max(ayrs), "_")
    # output name
    oname <- paste0(out, "/", areaname, yrs, "extent_summaries.csv")
    readr::write_csv(stats, path = oname)
  })
}

#' A function for calculating trend and trend class images
#'
#'  \code{trend_class} creates trend and trend class rasters from user specified
#'      time periods.
#'
#' @details Given an end year and a period length this function stacks the
#'     appropriate annual rasters and outputs a linear trend raster and a trend
#'     class raster based on a user supplied classification in csv format. The
#'     csv must have the following three column format so that each row forms a
#'     bin:
#' \itemize{
#'   \item lower - numerical low value for bin
#'   \item upper - numerical high value (<=) for bin
#'   \item reclass - numerical classification value
#'   }
#'     This classification is based on binning the slope values from the
#'     regression and is therefore sensitive to the period length. Ensure that
#'     the classification matches the intended period of analysis.
#'
#'     Note to accommodate any missing annual rasters, due to for example
#'     availability of suitable imagery, the function will create "dummy"
#'     rasters to pad the stack accordingly. These "dummy" rasters ensure the
#'     time variable is handled correctly in the regression. These "dummies" are
#'     deleted as the function cleans up after itself.
#'
#' @param irast Character file path to input veg density rasters that have been
#'     masked and found in either `veg_dens_mskd\` or `veg_dens_mskd_cld\`.
#' @param rastkey Character representation of unique string to match in intended
#'     rasters. This aids in not selecting additional files generated by other
#'     software (e.g. ArcMap).
#' @param end Numeric denoting final year of analysis.
#' @param period Numeric denoting intended length of trend analysis. Note that
#'     periods are matched to class bins so ensure that appropriate period
#'     length is entered otherwise results will be meaningless.
#' @param classes Character representation of the name of the trend class
#'     csv file including file path.
#'
#' @return A raster of slope values and a raster of trend classes are written to
#'     `trend_class\` for the intended period of analysis.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' trend_class(irast = "./veg_dens_mskd_for_trends", rastkey = ".tif",
#'     end = 2009, period = 10, classes = "./supplementary/trend_classes.csv")
#' }
#'
#' @import dplyr
#' @importFrom magrittr %>%
#' @importFrom fs dir_ls file_delete
#' @importFrom readr parse_number read_csv
#' @importFrom terra rast writeRaster  nlyr app classify
#' @importFrom stringr str_split str_replace
#'
#' @export
trend_class <- function(irast, rastkey, end, period, classes){
  suppressWarnings({
    ## Check for missing years...create dummies if required
    # get available raster names
    irs1 <- fs::dir_ls(irast, glob = paste0("*", rastkey, "$"))
    rastdf <- dplyr::tibble(path = as.character(irs1)) %>%
      dplyr::mutate(yr = readr::parse_number(basename(path)))
    # make generic raster name
    rstring <- irs1[[1]]
    numzap <- readr::parse_number(basename(rstring))
    gstring <- gsub(numzap, "XX", rstring)
    # find expected period
    start <- (end - (period - 1))
    true_period <- start:end
    # make an expected raster df
    dumdf <- dplyr::tibble(yr = true_period) %>%
      dplyr::mutate(path = stringr::str_replace(gstring, "XX", as.character(yr)))
    # df of missing rasters
    dum_rst <- dplyr::setdiff(dumdf, rastdf)
    # empty dummy raster
    blank <- terra::rast(terra::rast(irs1[1]))
    terra::values(blank) <- NA
    # write out dummy rasters if required
    if(nrow(dum_rst) > 0){
      cat("Dealing with dummy years... \n")
      for(i in seq_along(dum_rst[[2]])){
        nname <- dum_rst[[2]][i]
        terra::writeRaster(blank, nname, datatype = 'INT1U', overwrite = TRUE)
      }
    } else {
      cat("No missing years... \n")
    }

    cat("Doing trends now... \n")

    irs2 <- fs::dir_ls(irast, glob = paste0("*", rastkey, "$"))
    # make stack and sensible names
    stk <- terra::rast(irs2)
    s_layer_names <- readr::parse_number(basename(irs2))
    names(stk) <- s_layer_names
    # subset stack
    stk_e <- grep(pattern = end, names(stk))
    stk_s <- stk_e - (period - 1)
    trnd_stk <- stk[[stk_s:stk_e]]
    # output folder
    out <- "./trend_class"
    if (!file.exists(out)) {dir.create(out)}
    # per pixel lm
    time <- 1:terra::nlyr(trnd_stk)
    c_off <- ceiling(length(time)/2) # min data for lm choice
    lin_fun <- function(x) {
      if (sum(is.na(x)) > c_off) {
        NA
      } else {
        m = lm(x ~ time)
        m$coefficients[2]
      }
    }
    trend <- terra::app(trnd_stk, lin_fun)
    # get classes
    cl <- as.matrix(readr::read_csv(classes))
    # reclassify to trend class
    trnd_cl <- terra::classify(trend, cl)
    # name and save
    ayrs <- readr::parse_number(names(trnd_stk))
    yrs <- paste0("_", min(ayrs), "-", max(ayrs), "_")
    park <- unlist(stringr::str_split(basename(irs2[1]), "_"))[1]
    oname <- paste0(out, "/", park, "_mangroves", yrs, "trendclass", rastkey)
    tname <- paste0(out, "/", park, "_mangroves", yrs, "trend", rastkey)
    terra::writeRaster(trnd_cl, filename = oname, datatype = 'INT1U',
                       overwrite = TRUE)
    terra::writeRaster(trend, filename = tname, datatype = 'FLT4S',
                       overwrite = TRUE)
    ##Removal of dummies
    if(nrow(dum_rst) > 0){
      cat("Removing dummies... \n")
      for(i in seq_along(dum_rst[[2]])){
        tozap <- fs::dir_ls(irast, regexp = dum_rst[[2]][i])
        fs::file_delete(tozap)
      }
    } else {
      cat("No dummies to remove... \nAll finished... \n")
    }
  })
}

#' A function to calculate trend class classification area for reporting.
#'
#'  \code{change_extent} creates area stats for previously generated trend class
#'      rasters.
#'
#' @details This function is designed to calculate the area of each trend class
#'     as defined by using the \code{\link{trend_class}} per reporting area or
#'     site.Reporting areas are defined by input shape file. Outputs results to
#'     csv.
#'
#' @param irast Character file path to the trend class raster for a distinct period
#'     that has been written to the `trend_class\` directory. If multiple periods
#'     (and rasters) exist, run this one at a time.
#' @param iregions Character file path to a shape file (including extension)
#'     that defines reporting regions. The shape file should have an attribute
#'     column that defines the overall reporting "region" plus "site", if
#'     applicable, such as "NatPark_site1", "NatPark_site2" etc. The underscore
#'     delineates region from site.
#' @param attribname Character string of the name of the attribute column that
#'     contains the region information.
#'
#' @return Calculated areas are exported via csv file to `trend_class\`.
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' trend_class_areas(irast = "./trend_class/LgCSMP_mangroves_2005-2009_trendclass.img",
#'     iregions = "./vectors/regions.shp", attribname = "regions")
#' }
#'
#' @import dplyr
#' @importFrom magrittr %>%
#' @importFrom terra rast mask freq res rasterize
#' @importFrom tools file_path_sans_ext
#' @importFrom stringr str_split
#' @importFrom tibble as_tibble
#' @importFrom readr write_csv
#'
#' @export

trend_class_area <- function(irast, iregions, attribname){
  suppressWarnings({
    regions <- terra::vect(iregions)
    reps <- unique(regions[[attribname]][[1]])
    # trendclass raster
    tcs <- terra::rast(irast)
    # find pixel res and calculate hectares
    res_mult <- (round(terra::res(tcs)[1])^2)/10000
    out_list <- list()
    for(i in seq_along(reps)){
      # monitoring vector
      rep_i <- regions[i, attribname]
      name_r <- stringr::str_split(reps[i], "_")[[1]][1]
      name_s <- stringr::str_split(reps[i], "_")[[1]][2]
      cat(paste0("working on ", name_s, "...\n"))
      # make raster mask
      rep_ir <- terra::rasterize(rep_i, tcs)
      # mask out
      msk_ir <- terra::mask(x = tcs, mask = rep_ir)
      # calc freq
      stats <- tibble::as_tibble(terra::freq(msk_ir)) %>%
        dplyr::filter(!is.na(value)) %>%
        dplyr::mutate(Region = name_r,
                      Site = name_s,
                      Area = count * res_mult,
                      TrendClass = dplyr::case_when(
                        value == 1 ~ "Major Gain",
                        value == 2 ~ "Minor Gain",
                        value == 3 ~ "Stable",
                        value == 4 ~ "Minor Loss",
                        TRUE ~ "Major Loss"
                      )) %>%
        dplyr::select(-value, -count, -layer)
      out_list[[i]] <- stats
    }
    # output
    out_df <- do.call("rbind", out_list)
    o_name <- paste0(tools::file_path_sans_ext(irast), "_area_stats.csv")
    readr::write_csv(out_df, path = o_name)

  })
}

#' A function to calculate change extent area and generate change rasters for
#' reporting.
#'
#'  \code{change_extent} creates change rasters between all consecutive  vegetation
#'      classification rasters and summary area stats.
#'
#' @details This function is designed to do two things:
#'  \itemize{
#'   \item Firstly it creates change rasters between consecutive vegetation
#'       classification raster as produced by running \code{\link{veg_class}}. It
#'       summarises the densities into loss gain and stable categories in the
#'       output rasters.
#'   \item Secondly it generates area stats for regions and sites, defined by a
#'       user's shape file.
#'   }
#'
#' @param irast Character file path to input veg density rasters that have been
#'     through the veg classification process, i.e. those that are found in
#'     `veg_class\`.
#' @param rastkey Character representation of unique string to match in intended
#'     rasters. This aids in not selecting additional files generated by other
#'     software (e.g. ArcMap). It will also be the output format of any rasters.
#' @param iregions Character file path to a shape file (including extension)
#'     that defines reporting regions. The shape file should have an attribute
#'     column that defines the overall reporting "region" plus "site", if
#'     applicable, such as "NatPark_site1", "NatPark_site2" etc. The underscore
#'     delineates region from site.
#' @param attribname Character string of the name of the attribute column that
#'     contains the region information.
#' @param cloud Logical. Default is FALSE. If input imagery has  undergone
#'     groveR cloud masking choose TRUE. Can add significant processesing time
#'     on very large rasters.
#'
#'
#' @return Rasters and calculated areas are exported to `extent_change\`.
#'
#'
#' @author Bart Huntley, \email{bart.huntley@@dbca.wa.gov.au}
#'
#' @examples
#' \dontrun{
#' change_extent(irast = "./veg_class", rastkey = ".tif",
#'     iregions = "./vectors/regions.shp", attribname = "regions",
#'     cloud = FALSE)
#' }
#'
#' @import dplyr
#' @importFrom magrittr %>%
#' @importFrom fs dir_ls
#' @importFrom readr  write_csv
#' @importFrom stringr str_replace str_split
#' @importFrom sf st_as_sf st_area st_drop_geometry st_write
#' @importFrom terra rast vect crop rasterize mask classify ifel
#' @importFrom units set_units
#'
#' @export
change_extent <- function(irast, rastkey, iregions, attribname, cloud = FALSE){
  irs <- rev(fs::dir_ls(irast, glob = paste0("*", rastkey, "$")))
  rastdf <- dplyr::tibble(path = irs) %>%
    dplyr::mutate(yr = readr::parse_number(basename(path))) %>%
    dplyr::mutate(pathnew = stringr::str_replace(path, "veg_class",
                                                 "extent_change"),
                  pathnew1 = stringr::str_replace(pathnew, "Veg_Class", "extent_change"))
  out <- paste0("./", stringr::str_split(rastdf[[3]], "/")[[1]][2])

  end <- length(rastdf[[1]]) - 1
  rcl <- c(0, 1, 1, 1, 5, 2, 5, 6, 6, 6, 11, 7, 11, 15, 8,
           15, Inf, NA)
  rclm <- matrix(rcl, ncol = 3, byrow = TRUE)
  #out <- "./extent_change"
  out <- paste0("./", stringr::str_split(rastdf[[3]], "/")[[1]][2])
  if (!file.exists(out)) {
    dir.create(out)
  }
  whole_stack <- terra::rast(rastdf[["path"]])
  regions <- terra::vect(iregions)
  reps <- unique(regions[[attribname]][[1]])
  stats <- dplyr::tibble()
  for (i in seq_along(reps)){
    todo <- reps[i]
    rep_i <- regions[i, attribname]
    mini_crp <- terra::crop(whole_stack, rep_i)
    msk_i <- terra::rasterize(rep_i, mini_crp)
    min_msk <- terra::mask(mini_crp, msk_i)
    for (j in 1:end){
      cat("Calculating change between...", rastdf[[2]][j],
          "and", rastdf[[2]][j + 1], " for ",
          todo, "\n")
      b1 <- min_msk[[j]]
      a1 <- min_msk[[j + 1]]
      b <- terra::classify(b1, rclm)
      a <- terra::classify(a1, rclm)
      if (cloud == TRUE) {
        a10 <- terra::ifel(a == 1 & b == 2 | is.na(a) & b == 2, 10, 0)
        a11 <- terra::ifel(a == 2 & b == 1 | a == 2 & is.na(b), 11, 0)
        a12 <- terra::ifel(a == 2 & b == 2, 12, 0)
        a13 <- terra::ifel(a == 7 & b == 2 | a == 1 & b == 8 | a == 6 & b == 8 | a == 7 & b == 8 | is.na(a) & b == 8, 13, 0)
        a14 <- terra::ifel(a == 8 & b == 1 | a == 8 & b == 6 | a == 2 & b == 7 | a == 8 & b == 7 | a == 8 & is.na(b), 14, 0)
        a15 <- terra::ifel(a == 8 & b == 2 | a == 2 & b == 8 | a == 8 & b == 8, 15, 0)
        a16 <- terra::ifel(a == 6 & b == 2 | a == 2 & b == 6, 16, 0)
        ext_chng <- a10 + a11 + a12 + a13 + a14 + a15 + a16
        ext_chng <- terra::ifel(ext_chng != 0, ext_chng, NA)
      } else {
        a10 <- terra::ifel(a == 1 & b == 2 | is.na(a) & b == 2, 10, 0)
        a11 <- terra::ifel(a == 2 & b == 1 | a == 2 & is.na(b), 11, 0)
        a12 <- terra::ifel(a == 2 & b == 2, 12, 0)
        ext_chng <- a10 + a11 + a12
        ext_chng <- terra::ifel(ext_chng != 0, ext_chng, NA)
      }
      if(is.nan(terra::minmax(ext_chng)[[1]]) == FALSE) {
        v_chng <- sf::st_as_sf(terra::as.polygons(ext_chng))
        names(v_chng) <- c("gridcode", "geometry")
        au <- units::set_units(sf::st_area(v_chng), ha)
        period <- paste0(rastdf[[2]][j], "-", rastdf[[2]][j + 1])
        name_v <- paste0(out, "/", todo, "_", period, ".shp")
        v_dat_xy <- sf::st_write(dplyr::mutate(dplyr::mutate(v_chng,
                                                             status = dplyr::case_when(gridcode == 10 ~ "gain",
                                                                                       gridcode == 11 ~ "loss", gridcode == 12 ~ "stable", gridcode == 13 ~ "cloud likely gain",
                                                                                       gridcode == 14 ~ "cloud likely loss",
                                                                                       gridcode == 15 ~ "cloud likely stable",
                                                                                       gridcode == 16 ~ "cloud no data", TRUE ~  "other")),
                                               area_ha = au), dsn = name_v)
        name_r <- stringr::str_split(todo, "_")[[1]][1]
        name_s <- stringr::str_split(todo, "_")[[1]][2]
        v_dat_df <- dplyr::mutate(dplyr::rename(dplyr::select(dplyr::mutate(sf::st_drop_geometry(v_dat_xy),
                                                                            Region = name_r,
                                                                            Site = name_s,
                                                                            Period = period),
                                                              Region, Site,
                                                              area_ha, status,
                                                              Period),
                                                Area_ha = area_ha, Status = status),
                                  Area_ha = as.numeric(Area_ha))
        stats <- dplyr::bind_rows(stats, v_dat_df)
      } else {
        cat("No extent detected between...", rastdf[[2]][j], "and",
            rastdf[[2]][j + 1], " for ", todo, " moving on\n")
      }
    }
  }
  tofind <- tail(strsplit(rastdf[[4]][1], "_")[[1]],
                 n = 2)
  yr_rng <- paste0(min(rastdf[[2]]), "-" , max(rastdf[[2]]))

  cname <- stringr::str_replace(rastdf[[4]][1], tofind[1], "")

  cname2 <- stringr::str_replace(cname, paste0("_", tofind[2]),
                                 paste0(yr_rng, ".csv"))
  readr::write_csv(stats, file = cname2)
}
